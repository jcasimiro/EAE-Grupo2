n0 <- 3  # Número de nós iniciais
m <- 3   # Número de arestas que cada novo nó terá
n <- 6   # Número total de nós desejado na rede
# Criar uma rede inicial com n0 nós
g <- make_full_graph(n0)
# Crescer a rede adicionando um novo nó por vez
for(i in seq(n0 + 1, n)) {
# Inicializar o vetor de cores para os nós.
# Nota: As 11 cores permite ir até aos 11 nós, caso seja pretendido
# adicionar mais nós é preciso adicionar mais cores para o programa
# não dar erro.
cores <- c(
rgb(250/255, 251/255, 101/255),
rgb(232/255, 149/255, 112/255),
rgb(165/255, 164/255, 250/255),
rgb(197/255, 236/255, 250/255),
rgb(82/255, 67/255, 23/255),
rgb(203/255, 231/255, 104/255),
"red",
"blue",
"gray",
"coral",
"maroon"
)
# Recalcular o grau de cada nó existente
graus <- degree(g, mode = "all")
# Adicionar o novo nó (sempre branco)
g <- g + vertices(1)
# Colocar o nó adicionado como branco
cores[i] = "white"
# Remover as cores de nós não usados
n <- length(cores)-i
cores <- cores[-((length(cores)-n+1):length(cores))]
V(g)$color <- cores
# Calcular a probabilidade de conexão para cada nó existente
prob <- graus / sum(graus)
# Escolher m nós com base na probabilidade de conexão
nos_conectados <- sample(vcount(g) - 1, m, replace = FALSE, prob = prob)
# Conectar o novo nó aos nós escolhidos
arestas_novas <- c(sapply(nos_conectados, function(x) c(vcount(g), x)))
g <- g + edges(arestas_novas)
}
# Mostrar a rede
plot(g, vertex.size=5, vertex.label=NA, vertex.color=V(g)$color, asp=0)
# Carregar a biblioteca igraph
library(igraph)
# Parâmetros iniciais
n0 <- 3  # Número de nós iniciais
m <- 3   # Número de arestas que cada novo nó terá
n <- 6   # Número total de nós desejado na rede
# Criar uma rede inicial com n0 nós
g <- make_full_graph(n0)
# Crescer a rede adicionando um novo nó por vez
for(i in seq(n0 + 1, n)) {
# Inicializar o vetor de cores para os nós.
# Nota: As 11 cores permite ir até aos 11 nós, caso seja pretendido
# adicionar mais nós é preciso adicionar mais cores para o programa
# não dar erro.
cores <- c(
rgb(250/255, 251/255, 101/255),
rgb(232/255, 149/255, 112/255),
rgb(165/255, 164/255, 250/255),
rgb(197/255, 236/255, 250/255),
rgb(192/255, 155/255, 39/255),
rgb(203/255, 231/255, 104/255),
"red",
"blue",
"gray",
"coral",
"maroon"
)
# Recalcular o grau de cada nó existente
graus <- degree(g, mode = "all")
# Adicionar o novo nó (sempre branco)
g <- g + vertices(1)
# Colocar o nó adicionado como branco
cores[i] = "white"
# Remover as cores de nós não usados
n <- length(cores)-i
cores <- cores[-((length(cores)-n+1):length(cores))]
V(g)$color <- cores
# Calcular a probabilidade de conexão para cada nó existente
prob <- graus / sum(graus)
# Escolher m nós com base na probabilidade de conexão
nos_conectados <- sample(vcount(g) - 1, m, replace = FALSE, prob = prob)
# Conectar o novo nó aos nós escolhidos
arestas_novas <- c(sapply(nos_conectados, function(x) c(vcount(g), x)))
g <- g + edges(arestas_novas)
}
# Mostrar a rede
plot(g, vertex.size=5, vertex.label=NA, vertex.color=V(g)$color, asp=0)
# Carregar a biblioteca igraph
library(igraph)
# Parâmetros iniciais
n0 <- 3  # Número de nós iniciais
m <- 3   # Número de arestas que cada novo nó terá
n <- 7   # Número total de nós desejado na rede
# Criar uma rede inicial com n0 nós
g <- make_full_graph(n0)
# Crescer a rede adicionando um novo nó por vez
for(i in seq(n0 + 1, n)) {
# Inicializar o vetor de cores para os nós.
# Nota: As 11 cores permite ir até aos 11 nós, caso seja pretendido
# adicionar mais nós é preciso adicionar mais cores para o programa
# não dar erro.
cores <- c(
rgb(250/255, 251/255, 101/255),
rgb(232/255, 149/255, 112/255),
rgb(165/255, 164/255, 250/255),
rgb(197/255, 236/255, 250/255),
rgb(192/255, 155/255, 39/255),
rgb(203/255, 231/255, 104/255),
"red",
"blue",
"gray",
"coral",
"maroon"
)
# Recalcular o grau de cada nó existente
graus <- degree(g, mode = "all")
# Adicionar o novo nó (sempre branco)
g <- g + vertices(1)
# Colocar o nó adicionado como branco
cores[i] = "white"
# Remover as cores de nós não usados
n <- length(cores)-i
cores <- cores[-((length(cores)-n+1):length(cores))]
V(g)$color <- cores
# Calcular a probabilidade de conexão para cada nó existente
prob <- graus / sum(graus)
# Escolher m nós com base na probabilidade de conexão
nos_conectados <- sample(vcount(g) - 1, m, replace = FALSE, prob = prob)
# Conectar o novo nó aos nós escolhidos
arestas_novas <- c(sapply(nos_conectados, function(x) c(vcount(g), x)))
g <- g + edges(arestas_novas)
}
# Mostrar a rede
plot(g, vertex.size=5, vertex.label=NA, vertex.color=V(g)$color, asp=0)
install.packages(c("bslib", "callr", "dbplyr", "deldir", "digest", "fable", "feasts", "forecast", "future", "future.apply", "ggdist", "ggsci", "globals", "gmodels", "Hmisc", "htmltools", "httpuv", "igraph", "lattice", "lava", "lintr", "lme4", "pkgbuild", "processx", "ragg", "RcppArmadillo", "RcppEigen", "remotes", "rmarkdown", "rstudioapi", "sass", "shiny", "stinepack", "systemfonts", "tidyselect", "tinytex", "xfun"))
install.packages(c("Amelia", "brio", "explore", "fabletools", "fs", "ggfortify", "ggplot2", "gtable", "labelled", "lme4", "matrixStats", "openssl", "RcppArmadillo", "seriation", "styler", "survival", "testthat"))
setwd("~/Projects/EAE-Grupo2")
# No menu do RStudio:
# selecione Session > Set Working Directory > Choose Directory...
if (!requireNamespace("plot.matrix", quietly = TRUE))
install.packages("plot.matrix")
if (!requireNamespace("dbscan", quietly = TRUE))
install.packages("dbscan")
if (!requireNamespace("ggplot2", quietly = TRUE))
install.packages("ggplot2")
if (!requireNamespace("rpart", quietly = TRUE))
install.packages("rpart")
if (!requireNamespace("rpart.plot", quietly = TRUE))
install.packages("rpart.plot")
if (!requireNamespace("caret", quietly = TRUE))
install.packages("caret")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
if (!requireNamespace("pROC", quietly = TRUE))
install.packages("pROC")
if (!requireNamespace("e1071", quietly = TRUE))
install.packages("e1071")
if (!requireNamespace("foreach", quietly = TRUE))
install.packages("foreach")
if (!requireNamespace("doParallel", quietly = TRUE))
install.packages("doParallel")
if (!requireNamespace("doParallel", quietly = TRUE))
install.packages("factoextra")
library(plot.matrix)
library(dbscan)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(stats)
library(pROC)
library(e1071)
library(foreach)
library(doParallel)
library(factoextra)
# Function to show an image
plotfigure <<- function(row, dataset)
{
X = NULL
if (!is.null(nrow(dataset)))
{
X = data.frame(matrix(dataset[row, 2:785], nrow = 28))
}
else
{
X = data.frame(matrix(dataset[row, 2:785], nrow = 28))
}
m1 = data.matrix(X)
plot(m1, cex = 0.5)
}
# Read the training and testing dataset
train_data <<-
read.csv("emnist-balanced-train.csv",
sep = ",",
header = FALSE)
test_data <<-
read.csv("emnist-balanced-test.csv",
sep = ",",
header = FALSE)
# Labels of the characters we are going to work on
label_D <- 13
label_F <- 15
# Filter the training and testing datasets to contain only the "D" and "F" records
filtered_train_data <-
train_data[train_data$V1 %in% c(label_D, label_F),]
filtered_test_data <-
test_data[test_data$V1 %in% c(label_D, label_F),]
# ***** QUESTION 1 *****
# Create a decision tree on the training data set to obtain the most important
# pixels in separating the letters "D" and "F"
decision_tree_model <-
rpart(V1 ~ .,
data = filtered_train_data,
method = "class",
cp = 0.005)
# Show the decision tree
rpart.plot(
decision_tree_model,
main = "Árvore de Decisão - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
# Let's perform prediction to check the capability of the decision tree model
prediction_probs <-
predict(decision_tree_model, newdata = filtered_test_data, type = "prob")[, as.character(label_D)]
roc_obj <- roc(filtered_test_data$V1, prediction_probs)
plot(roc_obj)
coords(roc_obj, "best", ret = "threshold", best.method = "youden")
threshold <- 0.5
predicted_classes <-
ifelse(prediction_probs > threshold, label_D, label_F)
conf_matrix <-
table(Predicted = predicted_classes, Actual = filtered_test_data$V1)
conf_matrix_detailed <-
confusionMatrix(as.factor(predicted_classes),
as.factor(filtered_test_data$V1))
print(conf_matrix_detailed)
print("Root node:")
root_node <- decision_tree_model$frame[1,]
print(root_node)
par(mfrow = c(1, 1), mar = c(3, 3, 1, 1))
character_labels <-
ifelse(filtered_train_data$V1 == label_D, "D", "F")
boxplot(
as.matrix(filtered_train_data[root_node$var]) ~ character_labels,
main = paste(
"Distribuição dos Valores dos Pixels para 'D' e 'F' (Nó raiz: ",
root_node$var,
")"
),
col = c("red", "blue"),
las = 2,
xlab = "Letras",
ylab = "Intensidade dos pixeis"
)
print("Parent leaf node:")
leaf_nodes <-
decision_tree_model$frame[decision_tree_model$frame$var == "<leaf>",]
leaf_indices <- as.numeric(rownames(leaf_nodes))
parent_leaf_indices <- floor(leaf_indices / 2)
parent_leaf_nodes <-
decision_tree_model$frame[as.character(parent_leaf_indices),]
parent_leaf_node <- parent_leaf_nodes[5,]
print(parent_leaf_node)
boxplot(
as.matrix(filtered_train_data[parent_leaf_node$var]) ~ character_labels,
main = paste(
"Distribuição dos Valores dos Pixels para 'D' e 'F' (Nó folha: ",
parent_leaf_node$var,
")"
),
col = c("red", "blue"),
las = 2,
xlab = "Letras",
ylab = "Intensidade dos pixeis"
)
for (pixel in top_10_pixels) {
boxplot(as.matrix(filtered_train_data[pixel]) ~ character_labels,
main=paste("Distribuição dos Valores dos Pixels para 'D' e 'F' (Pixel: ", pixel, ")"),
col=c("red", "blue"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
}
variable_importance <- decision_tree_model$variable.importance
sorted_importance <- sort(variable_importance, decreasing = TRUE)
top_10_pixels <- names(sorted_importance)[1:10]
print("Os 10 pixeis mais importantes:")
print(top_10_pixels)
for (pixel in top_10_pixels) {
boxplot(as.matrix(filtered_train_data[pixel]) ~ character_labels,
main=paste("Distribuição dos Valores dos Pixels para 'D' e 'F' (Pixel: ", pixel, ")"),
col=c("red", "blue"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
}
filtered_train_data_dbscan <- filtered_train_data
train_data_DF <- filtered_train_data_dbscan[, -1]
dbscan_result <- dbscan(train_data_DF, eps = 0.1, minPts = 2)
filtered_train_data_dbscan$cluster <- dbscan_result$cluster
ggplot(filtered_train_data_dbscan, aes(x = V439, y = V496, color = as.factor(V1))) +
geom_point() +
labs(title = "DBSCAN Clustering para as Letras 'D' e 'F'",
x = "Pixel V439",
y = "Pixel V496",
color = "Cluster")
train_data_nb <- filtered_train_data[, -1]
train_labels_nb <- as.factor(filtered_train_data$V1)
model_nb <- naiveBayes(train_data_nb, train_labels_nb)
test_data_nb <- filtered_test_data[, -1]
test_labels_nb <- as.factor(filtered_test_data$V1)
predictions_nb <- predict(model_nb, test_data_nb)
conf_matrix_detailed <- confusionMatrix(predictions_nb, test_labels_nb)
print(conf_matrix_detailed)
train_data_pca <- filtered_test_data[, -1]
test_labels_pca <- as.factor(filtered_test_data$V1)
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca = prcomp(train_data_pca, scale. = TRUE)
train_data_pca_df <- data.frame(V1 = test_labels_pca, train_data_pca$x)
#names(train_data_pca$center)
decision_tree_model_pca <-
rpart(V1 ~ .,
data = train_data_pca_df,
method = "class",
cp = 0.01)
rpart.plot(
decision_tree_model_pca,
main = "Árvore de Decisão PCA - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
names(train_data_pca$center)
names(train_data_pca$x)
View(train_data_pca_df)
pca_coeficients <- train_data_pca$rotation
top_pca_pixels <- apply(abs(pca_coeficients), 1, sum)
top_pca_pixels <- sort(top_pca_pixels, decreasing = TRUE)
top_pca_10_pixels <- head(top_pca_pixels, 10)
print(top_pca_10_pixels)
top_pca_10_pixels_labels <- names(top_pca_10_pixels)
print(top_pca_10_pixels_labels)
for (pixel in top_pca_10_pixels_labels) {
boxplot(as.matrix(filtered_train_data[,pixel]) ~ character_labels,
main=paste("Distribuição dos Valores dos Pixels para 'D' e 'F' (Pixel: ", pixel, ")"),
col=c("red", "blue"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
}
explained_variance <- train_data_pca$sdev^2 / sum(train_data_pca$sdev^2) * 100
print(paste0("Variância explicada por cada componente: ", round(explained_variance, 2), "%"))
fviz_eig(train_data_pca, choice=c("variance"), ggtheme = theme_minimal(), title='Variância explicada')
View(train_data_pca)
train_data_pca <- filtered_test_data[, -1]
train_data_pca = prcomp(train_data_pca, scale. = TRUE)
View(train_data_pca)
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca = prcomp(train_data_pca, scale. = TRUE)
View(train_data_pca)
explained_variance <- train_data_pca$sdev^2 / sum(train_data_pca$sdev^2) * 100
print(paste0("Variância explicada por cada componente: ", round(explained_variance, 2), "%"))
fviz_eig(train_data_pca, choice=c("variance"), ggtheme = theme_minimal(), title='Variância explicada')
train_data_pca_df <- data.frame(V1 = test_labels_pca, train_data_pca$x)
train_data_svm <- filtered_train_data[, -1]
train_labels_svm <- as.factor(filtered_train_data$V1)
test_data_svm <- filtered_test_data[, -1]
test_labels_svm <- as.factor(filtered_test_data$V1)
execute_svm(train_data_svm, train_labels_svm, test_data_svm, test_labels_svm)
execute_svm <<- function(train_data, train_labels, test_data, test_labels)
{
svm_model <- svm(train_data, train_labels, type = 'C-classification', kernel="linear")
predictions <- predict(svm_model, test_data)
conf_matrix_detailed <- confusionMatrix(predictions, test_labels)
print(conf_matrix_detailed)
}
train_data_svm <- filtered_train_data[, -1]
train_labels_svm <- as.factor(filtered_train_data$V1)
test_data_svm <- filtered_test_data[, -1]
test_labels_svm <- as.factor(filtered_test_data$V1)
execute_svm(train_data_svm, train_labels_svm, test_data_svm, test_labels_svm)
train_data_svm_pca <- prcomp(train_data_svm, scale. = TRUE)
train_data_svm <- train_data_svm[, apply(train_data_svm, 2, var) != 0]
test_data_svm <- test_data_svm[, apply(test_data_svm, 2, var) != 0]
train_data_svm_pca <- prcomp(train_data_svm, scale. = TRUE)
test_data_svm_pca <- prcomp(test_data_svm, scale. = TRUE)
execute_svm(train_data_svm_pca$x, train_labels_svm, test_data_svm_pca$x, test_labels_svm)
filtered_train_data_dbscan <- filtered_train_data
train_data_DF <- filtered_train_data_dbscan[, -1]
dbscan_result <- dbscan(train_data_DF, eps = 0.1, minPts = 2)
filtered_train_data_dbscan$cluster <- dbscan_result$cluster
ggplot(filtered_train_data_dbscan, aes(x = V439, y = V496, color = as.factor(V1))) +
geom_point() +
labs(title = "DBSCAN Clustering para as Letras 'D' e 'F'",
x = "Pixel V439",
y = "Pixel V496",
color = "Cluster")
decision_tree_model <-
rpart(V1 ~ .,
data = filtered_train_data,
method = "class",
cp = 0.005)
# Show the decision tree
rpart.plot(
decision_tree_model,
main = "Árvore de Decisão - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
prediction_probs <-
predict(decision_tree_model, newdata = filtered_test_data, type = "prob")[, as.character(label_D)]
roc_obj <- roc(filtered_test_data$V1, prediction_probs)
plot(roc_obj)
coords(roc_obj, "best", ret = "threshold", best.method = "youden")
threshold <- 0.5
predicted_classes <-
ifelse(prediction_probs > threshold, label_D, label_F)
conf_matrix <-
table(Predicted = predicted_classes, Actual = filtered_test_data$V1)
conf_matrix_detailed <-
confusionMatrix(as.factor(predicted_classes),
as.factor(filtered_test_data$V1))
print(conf_matrix_detailed)
decision_tree_model <-
rpart(V1 ~ .,
data = filtered_train_data,
method = "class")
# Show the decision tree
rpart.plot(
decision_tree_model,
main = "Árvore de Decisão - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
prediction_probs <-
predict(decision_tree_model, newdata = filtered_test_data, type = "prob")[, as.character(label_D)]
roc_obj <- roc(filtered_test_data$V1, prediction_probs)
plot(roc_obj)
coords(roc_obj, "best", ret = "threshold", best.method = "youden")
threshold <- 0.5
predicted_classes <-
ifelse(prediction_probs > threshold, label_D, label_F)
conf_matrix <-
table(Predicted = predicted_classes, Actual = filtered_test_data$V1)
conf_matrix_detailed <-
confusionMatrix(as.factor(predicted_classes),
as.factor(filtered_test_data$V1))
print(conf_matrix_detailed)
train_data_pca <- filtered_test_data[, -1]
test_labels_pca <- as.factor(filtered_test_data$V1)
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca = prcomp(train_data_pca, scale. = TRUE)
explained_variance <- train_data_pca$sdev^2 / sum(train_data_pca$sdev^2) * 100
print(paste0("Variância explicada por cada componente: ", round(explained_variance, 2), "%"))
fviz_eig(train_data_pca, choice=c("variance"), ggtheme = theme_minimal(), title='Variância explicada')
train_data_pca_df <- data.frame(V1 = test_labels_pca, train_data_pca$x)
names(train_data_pca$x)
decision_tree_model_pca <-
rpart(V1 ~ .,
data = train_data_pca_df,
method = "class",
cp = 0.01)
rpart.plot(
decision_tree_model_pca,
main = "Árvore de Decisão PCA - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
pca_coeficients <- train_data_pca$rotation
top_pca_pixels <- apply(abs(pca_coeficients), 1, sum)
top_pca_pixels <- sort(top_pca_pixels, decreasing = TRUE)
top_pca_10_pixels <- head(top_pca_pixels, 10)
print(top_pca_10_pixels)
top_pca_10_pixels_labels <- names(top_pca_10_pixels)
print(top_pca_10_pixels_labels)
for (pixel in top_pca_10_pixels_labels) {
boxplot(as.matrix(filtered_train_data[,pixel]) ~ character_labels,
main=paste("Distribuição dos Valores dos Pixels para 'D' e 'F' (Pixel: ", pixel, ")"),
col=c("red", "blue"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
}
pca_coeficients <- train_data_pca$rotation
top_pca_pixels <- apply(abs(pca_coeficients), 1, sum)
top_pca_pixels <- sort(top_pca_pixels, decreasing = TRUE)
top_pca_10_pixels <- head(top_pca_pixels, 10)
print(top_pca_10_pixels)
top_pca_10_pixels_labels <- names(top_pca_10_pixels)
print(top_pca_10_pixels_labels)
explained_variance <- train_data_pca$sdev^2 / sum(train_data_pca$sdev^2) * 100
print(paste0("Variância explicada por cada componente: ", round(explained_variance, 2), "%"))
fviz_eig(train_data_pca, choice=c("variance"), ggtheme = theme_minimal(), title='Variância explicada')
View(decision_tree_model)
top_pca_pixels
apply(abs(pca_coeficients), 1, sum)
View(decision_tree_model)
decision_tree_model$frame[decision_tree_model$frame$var == "<leaf>",]
decision_tree_model$frame[decision_tree_model$frame$var == "<leaf>",]
decision_tree_model$frame[1,]
