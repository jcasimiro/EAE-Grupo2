setwd("C:/Users/josea/Projects/EAE-Grupo2")
knitr::opts_chunk$set(echo = TRUE)
if (!requireNamespace("plot.matrix", quietly = TRUE))
install.packages("plot.matrix")
if (!requireNamespace("dbscan", quietly = TRUE))
install.packages("dbscan")
if (!requireNamespace("ggplot2", quietly = TRUE))
install.packages("ggplot2")
if (!requireNamespace("rpart", quietly = TRUE))
install.packages("rpart")
if (!requireNamespace("rpart.plot", quietly = TRUE))
install.packages("rpart.plot")
if (!requireNamespace("caret", quietly = TRUE))
install.packages("caret")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
if (!requireNamespace("pROC", quietly = TRUE))
install.packages("pROC")
if (!requireNamespace("e1071", quietly = TRUE))
install.packages("e1071")
if (!requireNamespace("foreach", quietly = TRUE))
install.packages("foreach")
if (!requireNamespace("dplyr", quietly = TRUE))
install.packages("dplyr")
if (!requireNamespace("factoextra", quietly = TRUE))
install.packages("factoextra")
if (!requireNamespace("cluster", quietly = TRUE))
install.packages("cluster")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
library(plot.matrix)
library(dbscan)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(stats)
library(pROC)
library(e1071)
library(foreach)
library(doParallel)
library(dplyr)
library(naivebayes)
library(factoextra)
library(cluster)
library(stats)
plotfigure <<- function(row,dataset)
{
X = NULL
if(!is.null(nrow(dataset)))
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
else
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
m1 = data.matrix(X)
plot(m1, cex=0.5)
}
set.seed(123)
modelo_arvore <- rpart(V1 ~ ., data = filtered_train_data, method = "class")
knitr::opts_chunk$set(echo = TRUE)
if (!requireNamespace("plot.matrix", quietly = TRUE))
install.packages("plot.matrix")
if (!requireNamespace("dbscan", quietly = TRUE))
install.packages("dbscan")
if (!requireNamespace("ggplot2", quietly = TRUE))
install.packages("ggplot2")
if (!requireNamespace("rpart", quietly = TRUE))
install.packages("rpart")
if (!requireNamespace("rpart.plot", quietly = TRUE))
install.packages("rpart.plot")
if (!requireNamespace("caret", quietly = TRUE))
install.packages("caret")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
if (!requireNamespace("pROC", quietly = TRUE))
install.packages("pROC")
if (!requireNamespace("e1071", quietly = TRUE))
install.packages("e1071")
if (!requireNamespace("foreach", quietly = TRUE))
install.packages("foreach")
if (!requireNamespace("dplyr", quietly = TRUE))
install.packages("dplyr")
if (!requireNamespace("factoextra", quietly = TRUE))
install.packages("factoextra")
if (!requireNamespace("cluster", quietly = TRUE))
install.packages("cluster")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
library(plot.matrix)
library(dbscan)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(stats)
library(pROC)
library(e1071)
library(foreach)
library(doParallel)
library(dplyr)
library(naivebayes)
library(factoextra)
library(cluster)
library(stats)
plotfigure <<- function(row,dataset)
{
X = NULL
if(!is.null(nrow(dataset)))
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
else
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
m1 = data.matrix(X)
plot(m1, cex=0.5)
}
train_data <<- read.csv("emnist-balanced-train.csv",sep=",",header = FALSE)
test_data <<- read.csv("emnist-balanced-test.csv",sep=",",header = FALSE)
par(mfrow = c(2, 2))
plotfigure(14,train_data)
plotfigure(60,train_data)
plotfigure(13,train_data)
plotfigure(4,train_data)
label_D <- 13
label_F <- 15
filtered_train_data <- train_data[train_data$V1 %in% c(label_D, label_F), ]
filtered_test_data <- test_data[test_data$V1 %in% c(label_D, label_F), ]
head(filtered_train_data[, 1:5], 5)
filtered_train_data$V1 <-as.factor(filtered_train_data$V1)
filtered_test_data$V1 <-as.factor(filtered_test_data$V1)
set.seed(123)
modelo_arvore <- rpart(V1 ~ ., data = filtered_train_data, method = "class")
rpart.plot(modelo_arvore,
main="Arvore de Decisao - 'D' vs 'F'",
box.palette = "RdBu",
type = 2,
extra = 104)
plotcp(modelo_arvore, upper = "splits")
# No menu do RStudio:
# selecione Session > Set Working Directory > Choose Directory...
if (!requireNamespace("plot.matrix", quietly = TRUE))
install.packages("plot.matrix")
if (!requireNamespace("dbscan", quietly = TRUE))
install.packages("dbscan")
if (!requireNamespace("ggplot2", quietly = TRUE))
install.packages("ggplot2")
if (!requireNamespace("rpart", quietly = TRUE))
install.packages("rpart")
if (!requireNamespace("rpart.plot", quietly = TRUE))
install.packages("rpart.plot")
if (!requireNamespace("caret", quietly = TRUE))
install.packages("caret")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
if (!requireNamespace("pROC", quietly = TRUE))
install.packages("pROC")
if (!requireNamespace("e1071", quietly = TRUE))
install.packages("e1071")
if (!requireNamespace("foreach", quietly = TRUE))
install.packages("foreach")
if (!requireNamespace("doParallel", quietly = TRUE))
install.packages("doParallel")
if (!requireNamespace("factoextra", quietly = TRUE))
install.packages("factoextra")
if (!requireNamespace("cluster", quietly = TRUE))
install.packages("cluster")
library(plot.matrix)
library(dbscan)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(stats)
library(pROC)
library(e1071)
library(foreach)
library(doParallel)
library(factoextra)
library(cluster)
# Function to show an image
plotfigure <<- function(row, dataset)
{
X = NULL
if (!is.null(nrow(dataset)))
{
X = data.frame(matrix(dataset[row, 2:785], nrow = 28))
}
else
{
X = data.frame(matrix(dataset[row, 2:785], nrow = 28))
}
m1 = data.matrix(X)
plot(m1, cex = 0.5)
}
# Read the training and testing dataset
train_data <<-
read.csv("emnist-balanced-train.csv",
sep = ",",
header = FALSE)
test_data <<-
read.csv("emnist-balanced-test.csv",
sep = ",",
header = FALSE)
# Labels of the characters we are going to work on
label_D <- 13
label_F <- 15
# Filter the training and testing datasets to contain only the "D" and "F" records
filtered_train_data <-
train_data[train_data$V1 %in% c(label_D, label_F),]
filtered_test_data <-
test_data[test_data$V1 %in% c(label_D, label_F),]
result <- shapiro.test()
execute_svm <<- function(train_data, train_labels, test_data, test_labels)
{
svm_model <- svm(train_data, train_labels, type = 'C-classification', kernel="linear")
predictions <- predict(svm_model, test_data)
conf_matrix_detailed <- confusionMatrix(predictions, test_labels)
print(conf_matrix_detailed)
}
# Let's combine the training and testing datasets in just one
filtered_combined_data <- rbind(filtered_train_data, filtered_test_data)
# Remove columns with zero variance
filtered_combined_data <- filtered_combined_data[, apply(filtered_combined_data, 2, var) != 0]
# Perform PCA on the combined data with scaling
filtered_combined_data_pca <- prcomp(filtered_combined_data, scale. = TRUE)
# Split filtered_combined_data into training and testing sets
train_indices <- 1:4800
test_indices <- 4801:5600
filtered_train_data_split <- filtered_combined_data[train_indices, ]
filtered_test_data_split <- filtered_combined_data[test_indices, ]
# Split filtered_combined_data_pca into training and testing sets
filtered_train_data_pca_split <- filtered_combined_data_pca$x[train_indices, ]
filtered_test_data_pca_split <- filtered_combined_data_pca$x[test_indices, ]
# Classification without PCA
train_data_svm <- filtered_train_data_split[, -1]
train_labels_svm <- as.factor(filtered_train_data_split$V1)
test_data_svm <- filtered_test_data_split[, -1]
test_labels_svm <- as.factor(filtered_test_data_split$V1)
execute_svm(train_data_svm, train_labels_svm, test_data_svm, test_labels_svm)
# Classification with PCA
train_data_svm_pca <- filtered_train_data_pca_split
train_labels_svm_pca <- as.factor(filtered_train_data_split$V1)
test_data_svm_pca <- filtered_test_data_pca_split
test_labels_svm_pca <- as.factor(filtered_test_data_split$V1)
execute_svm(train_data_svm_pca, train_labels_svm_pca, test_data_svm_pca, test_labels_svm_pca)
# Filter the first two principal components
pca_data <- train_data_pca$x[, 1:2]
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "complete")
# Plot the dendrogram
plot(hc, main = "Dendrograma - Clustering Hierárquico", xlab = "", sub = "")
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "complete")
pca_data <- train_data_pca$x[, 1:2]
train_data_pca <- filtered_test_data[, -1]
test_labels_pca <- as.factor(filtered_test_data$V1)
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca = prcomp(train_data_pca, scale. = TRUE)
explained_variance <- train_data_pca$sdev^2 / sum(train_data_pca$sdev^2) * 100
print(paste0("Variância explicada por cada componente: ", round(explained_variance, 2), "%"))
fviz_eig(train_data_pca, choice=c("variance"), ggtheme = theme_minimal(), title='Variância explicada')
train_data_pca_df <- data.frame(V1 = test_labels_pca, train_data_pca$x)
names(train_data_pca$x)
decision_tree_model_pca <-
rpart(V1 ~ .,
data = train_data_pca_df,
method = "class",
cp = 0.01)
rpart.plot(
decision_tree_model_pca,
main = "Árvore de Decisão PCA - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
pca_coeficients <- train_data_pca$rotation
top_pca_pixels <- apply(abs(pca_coeficients), 1, sum)
top_pca_pixels <- sort(top_pca_pixels, decreasing = TRUE)
top_pca_10_pixels <- head(top_pca_pixels, 10)
print(top_pca_10_pixels)
top_pca_10_pixels_labels <- names(top_pca_10_pixels)
print(top_pca_10_pixels_labels)
for (pixel in top_pca_10_pixels_labels) {
boxplot(as.matrix(filtered_train_data[,pixel]) ~ character_labels,
main=paste("Distribuição dos Valores dos Pixels para 'D' e 'F' (Pixel: ", pixel, ")"),
col=c("red", "blue"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
}
# Filter the first two principal components
pca_data <- train_data_pca$x[, 1:2]
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "complete")
# Plot the dendrogram
plot(hc, main = "Dendrograma - Clustering Hierárquico", xlab = "", sub = "")
k_values <- 2:10  # Test different numbers of clusters (adjust as needed)
hc_clusters <- lapply(k_values, function(k) cutree(hc, k = k))
# 2. Calculate silhouette scores for each cluster solution
silhouette_scores <- sapply(hc_clusters, function(clusters) {
mean(silhouette(clusters, dist(pca_data))[, 3])
})
# 3. Create a dataframe for visualization
sil_df <- data.frame(
k = k_values,
silhouette = silhouette_scores
)
# 4. Visualize silhouette scores
fviz_nbclust(sil_df, x = "k", y = "silhouette", type = "b", geom = "line") +
labs(x = "Number of Clusters", y = "Average Silhouette Width")
# 4. Visualize silhouette scores
ggplot(sil_df, aes(x = k, y = silhouette)) +
geom_line() +
geom_point() +  # Add points to highlight each k value
labs(x = "Number of Clusters", y = "Average Silhouette Width")
k_values <- 1:4  # Test different numbers of clusters (adjust as needed)
hc_clusters <- lapply(k_values, function(k) cutree(hc, k = k))
# 2. Calculate silhouette scores for each cluster solution
silhouette_scores <- sapply(hc_clusters, function(clusters) {
mean(silhouette(clusters, dist(pca_data))[, 3])
})
silhouette(clusters, dist(pca_data))
# 2. Calculate silhouette scores for each cluster solution
silhouette_scores <- sapply(hc_clusters, function(clusters) {
mean(silhouette(clusters, dist(pca_data))[, 1])
})
# 3. Create a dataframe for visualization
sil_df <- data.frame(
k = k_values,
silhouette = silhouette_scores
)
# 4. Visualize silhouette scores
ggplot(sil_df, aes(x = k, y = silhouette)) +
geom_line() +
geom_point() +  # Add points to highlight each k value
labs(x = "Number of Clusters", y = "Average Silhouette Width")
# 3. Create Comparison Data Frame
comparison_df_hc <- data.frame(
True_Labels = filtered_test_data$V1,
Predicted_Clusters = hc_clusters[1:nrow(filtered_test_data)]
)
hc_clusters <- cutree(hc, k = num_clusters)
# 3. Create Comparison Data Frame
comparison_df_hc <- data.frame(
True_Labels = filtered_test_data$V1,
Predicted_Clusters = hc_clusters[1:nrow(filtered_test_data)]
)
# 3. Create Comparison Data Frame
comparison_df_hc <- data.frame(
True_Labels = filtered_test_data$V1,
Predicted_Clusters = hc_clusters
)
# 4. Print the Comparison
print(head(comparison_df_hc, 20))
hc_clusters <- cutree(hc, k = 2)
# 3. Create Comparison Data Frame
comparison_df_hc <- data.frame(
True_Labels = filtered_test_data$V1,
Predicted_Clusters = hc_clusters
)
# 4. Print the Comparison
print(head(comparison_df_hc, 20))
