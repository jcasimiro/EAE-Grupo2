train_data_pca_df <- data.frame(V1 = test_labels_pca, train_data_pca$x)
names(train_data_pca$x)
decision_tree_model_pca <-
rpart(V1 ~ .,
data = train_data_pca_df,
method = "class",
cp = 0.01)
rpart.plot(
decision_tree_model_pca,
main = "Árvore de Decisão PCA - 'D' vs 'F'",
cex.sub = 1.5,
cex.main = 1
)
loadings_pc1 <- pca_model$rotation[, 1]
# PCA apenas nos dados de treino
train_data_pca <- filtered_train_data[, -1]
# Normalização dos dados
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca_scaled <- scale(train_data_pca)
# Realizar PCA
pca_model <- prcomp(train_data_pca_scaled)
# Variância explicada por cada componente principal
explained_variance <- pca_model$sdev^2 / sum(pca_model$sdev^2) * 100
cat("Variância explicada pela primeira componente principal:", round(explained_variance[1], 2), "%\n")
# Gráfico da variância explicada por cada componente principal
fviz_eig(pca_model, choice = "variance", ggtheme = theme_minimal(), title = "Variância Explicada por Componente Principal")
# Carregamentos da primeira componente principal
loadings_pc1 <- pca_model$rotation[, 1]
# Encontrar os 10 pixels com os maiores pesos absolutos na primeira componente principal
top_10_pixels <- head(sort(abs(loadings_pc1), decreasing = TRUE), 10)
cat("\n10 pixels mais importantes na primeira componente principal:\n")
print(top_10_pixels)
# Criar um vetor com os nomes dos pixels mais e menos importantes
all_pixels <- c(names(top_10_pixels), names(bottom_10_pixels))
# Criar um vetor com os nomes dos pixels mais importantes
all_pixels <- c(names(top_10_pixels))
for (pixel_name in all_pixels) {
pixel_values <- filtered_train_data[, pixel_name]
# Criar um dataframe para o boxplot
boxplot_df <- data.frame(
Intensidade = pixel_values,
Letra = character_labels  # Rótulos das letras ('D' ou 'F')
)
# Criar e exibir o boxplot
boxplot(Intensidade ~ Letra, data = boxplot_df,
main = paste("Distribuição da Intensidade do Pixel", pixel_name),
xlab = "Letra", ylab = "Intensidade do Pixel",
col = c("blue", "red"))
}
train_data_nb <- filtered_train_data_pixels_to_keep[, -1]
train_labels_nb <- as.factor(filtered_train_data_pixels_to_keep$V1)
for (pixel in names(train_data_nb)) {
# Filtrar dados para a letra 'D' (label_D = 13)
train_data_D <- train_data_nb[train_labels_nb == label_D, ][[pixel]]
# Filtrar dados para a letra 'F' (label_F = 15)
train_data_F <- train_data_nb[train_labels_nb == label_F, ][[pixel]]
# Teste de Shapiro-Wilk para a letra 'D'
shapiro_result_D <- shapiro.test(train_data_D)
cat("Pixel:", pixel, "- Letra D\n")
cat("Estatística W:", shapiro_result_D$statistic, "\n")
cat("Valor-p:", shapiro_result_D$p.value, "\n\n")
# Teste de Shapiro-Wilk para a letra 'F'
shapiro_result_F <- shapiro.test(train_data_F)
cat("Pixel:", pixel, "- Letra F\n")
cat("Estatística W:", shapiro_result_F$statistic, "\n")
cat("Valor-p:", shapiro_result_F$p.value, "\n\n")
}
# Classificação Naive Bayes Paramétrica (já existente)
model_nb_parametric <- naive_bayes(train_data_nb, train_labels_nb)
predictions_nb_parametric <- predict(model_nb_parametric, test_data_nb, type = "class")
# Classificação Naive Bayes Não Paramétrica
model_nb_nonparametric <- naive_bayes(train_data_nb, train_labels_nb, usekernel = TRUE, kernel = "gaussian")
predictions_nb_nonparametric <- predict(model_nb_nonparametric, test_data_nb, type = "class")
#Tipos de Kernel:
#gaussian: Kernel Gaussiano (padrão)
#rectangular: Kernel Retangular (ou Uniforme)
#triangular: Kernel Triangular
#epanechnikov: Kernel Epanechnikov
#biweight: Kernel Biweight (ou Quartic)
#cosine: Kernel Cosseno
#optcosine: Kernel Cosseno Otimizado
# Comparação dos Resultados
cat("\nMatriz de Confusão - Naive Bayes Paramétrico:\n")
conf_matrix_detailed_parametric <- confusionMatrix(predictions_nb_parametric, test_labels_nb)
print(conf_matrix_detailed_parametric)
cat("\nMatriz de Confusão - Naive Bayes Não Paramétrico:\n")
conf_matrix_detailed_nonparametric <- confusionMatrix(predictions_nb_nonparametric, test_labels_nb)
print(conf_matrix_detailed_nonparametric)
setwd("~/Projects/EAE-Grupo2")
if (!requireNamespace("plot.matrix", quietly = TRUE))
install.packages("plot.matrix")
if (!requireNamespace("dbscan", quietly = TRUE))
install.packages("dbscan")
if (!requireNamespace("ggplot2", quietly = TRUE))
install.packages("ggplot2")
if (!requireNamespace("rpart", quietly = TRUE))
install.packages("rpart")
if (!requireNamespace("rpart.plot", quietly = TRUE))
install.packages("rpart.plot")
if (!requireNamespace("caret", quietly = TRUE))
install.packages("caret")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
if (!requireNamespace("pROC", quietly = TRUE))
install.packages("pROC")
if (!requireNamespace("e1071", quietly = TRUE))
install.packages("e1071")
if (!requireNamespace("foreach", quietly = TRUE))
install.packages("foreach")
if (!requireNamespace("library(dplyr)", quietly = TRUE))
install.packages("library(dplyr)")
if (!requireNamespace("factoextra", quietly = TRUE))
install.packages("factoextra")
if (!requireNamespace("cluster", quietly = TRUE))
install.packages("cluster")
if (!requireNamespace("stats", quietly = TRUE))
install.packages("stats")
library(plot.matrix)
library(dbscan)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(stats)
library(pROC)
library(e1071)
library(foreach)
library(doParallel)
library(dplyr)
library(naivebayes)
library(factoextra)
library(cluster)
library(stats)
plotfigure <<- function(row,dataset)
{
X = NULL
if(!is.null(nrow(dataset)))
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
else
{
X = data.frame(matrix(dataset[row,2:785],nrow=28))
}
m1 = data.matrix(X)
plot(m1, cex=0.5)
}
train_data <<- read.csv("emnist-balanced-train.csv",sep=",",header = FALSE)
test_data <<- read.csv("emnist-balanced-test.csv",sep=",",header = FALSE)
par(mfrow = c(2, 2))
plotfigure(14,train_data)
plotfigure(60,train_data)
plotfigure(13,train_data)
plotfigure(4,train_data)
label_D <- 13
label_F <- 15
filtered_train_data <- train_data[train_data$V1 %in% c(label_D, label_F), ]
filtered_test_data <- test_data[test_data$V1 %in% c(label_D, label_F), ]
head(filtered_train_data[, 1:5], 5)
set.seed(123)
modelo_arvore <- rpart(V1 ~ ., data = filtered_train_data, method = "class")
rpart.plot(modelo_arvore,
main="Árvore de Decisão - 'D' vs 'F'",
box.palette = "RdBu",
type = 2,
extra = 104)
set.seed(123)
modelo_arvore <- rpart(V1 ~ ., data = filtered_train_data, method = "class")
rpart.plot(modelo_arvore,
main="Árvore de Decisão - 'D' vs 'F'",
box.palette = "RdBu",
type = 2,
extra = 104)
plotcp(modelo_arvore, upper = "splits")
prediction_probs <- predict(modelo_arvore, newdata = filtered_test_data, type = "prob")[, as.character(label_D)]
# Curva ROC
roc_obj <- roc(filtered_test_data$V1, prediction_probs)
plot(roc_obj,
axes=FALSE,
print.auc.col = "#CC6699",
col = "#CC6699",
ylab = "Sensibilidade",
xlab = "1-Especificidade")
axis(side = 2, at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
labels = expression(0, 0.2, 0.4, 0.6, 0.8, 1), cex.axis = 1, pos=1)
axis(side = 1, at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
labels = expression(1, 0.8, 0.6, 0.4, 0.2, 0),
pos=-0.001,
cex.axis = 1)
coords(roc_obj, "best", ret = "threshold", best.method = "youden")
threshold <- 0.5
predicted_classes <- ifelse(prediction_probs > threshold, label_D, label_F)
# Matriz de Confusão
conf_matrix <- table(Predicted = predicted_classes, Actual = filtered_test_data$V1)
conf_matrix_detailed <- confusionMatrix(as.factor(predicted_classes), as.factor(filtered_test_data$V1))
print(conf_matrix_detailed)
par(mfrow = c(1, 2))
filtered_data_13 <- filtered_train_data %>%
filter(V1 == 13)
filtered_data_15 <- filtered_train_data %>%
filter(V1 == 15)
filtered_data_13$group <- "D"
filtered_data_15$group <- "F"
combined_data <- rbind(filtered_data_13, filtered_data_15)
ggplot(combined_data, aes(x = V554, fill = group)) +
geom_density(alpha = 0.6) +
scale_fill_manual(values = c("blue", "red")) +
theme_minimal() +
labs(x = "Valor do Pixel", y = "Densidade", title = "Gráfico de Dendidade para o Pixel 554") +
guides(fill = guide_legend(title = "Grupo")) +
geom_vline(xintercept = 1, linetype = "dashed", color = "black")
character_labels <- ifelse(filtered_train_data$V1 == label_D, "D", "F")
boxplot(as.matrix(filtered_train_data[,554:554]) ~ character_labels,
col=c("#FF9966", "#996633"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
title(main = "Distribuição dos Valores dos Pixels para 'D' e 'F'", cex.main = 0.7)
ggplot(combined_data, aes(x = V604, fill = group)) +
geom_density(alpha = 0.6) +
scale_fill_manual(values = c("blue", "red")) +
theme_minimal() +
labs(x = "Valor do Pixel", y = "Densidade", title = "Gráfico de Dendidade para o Pixel 604") +
guides(fill = guide_legend(title = "Grupo")) +
geom_vline(xintercept = 1, linetype = "dashed", color = "black") +
coord_cartesian(ylim = c(0, 0.10))
boxplot(as.matrix(filtered_train_data[,604:604]) ~ character_labels,
col=c("#FF9966", "#996633"),
las=2,
xlab="Letras",
ylab="Intensidade dos pixeis",
#outline=FALSE
)
title(main = "Distribuição dos Valores dos Pixels para 'D' e 'F'", cex.main = 0.7)
# Distâncias entre pontos
sums_D <- colSums(filtered_train_data[filtered_train_data$V1 == label_D, -1])
sums_F <- colSums(filtered_train_data[filtered_train_data$V1 == label_F, -1])
differences <- abs(sums_D - sums_F)
db <- rbind(filtered_train_data, differences)
plotfigure(4801, db)
# Distâncias entre pontos
sums_D <- colSums(filtered_train_data[filtered_train_data$V1 == label_D, -1])
sums_F <- colSums(filtered_train_data[filtered_train_data$V1 == label_F, -1])
differences <- abs(sums_D - sums_F)
db <- rbind(filtered_train_data, differences)
plotfigure(4801, db)
differences[554] = 50
differences[640] = 260000
differences[496] = 50
differences[604] = 50
db <- rbind(filtered_train_data, differences)
plotfigure(4801, db)
# Pixeis escolhidps
decision_nodes <-
modelo_arvore$frame[modelo_arvore$frame$var != "<leaf>",]
pixels_to_keep <- c("V1", decision_nodes$var)
# Nova base de dados com os pixeis escolhidos
filtered_train_data_pixels_to_keep <- filtered_train_data[, pixels_to_keep]
filtered_test_data_pixels_to_keep <- filtered_test_data[, pixels_to_keep]
hist(filtered_data_13$V554)
hist(filtered_data_15$V554)
hist(filtered_data_13$V640)
hist(filtered_data_15$V640)
hist(filtered_data_13$V496)
hist(filtered_data_15$V496)
hist(filtered_data_13$V604)
hist(filtered_data_15$V604)
filtered_train_data_dbscan <- filtered_train_data_pixels_to_keep
train_data_DF <- filtered_train_data_dbscan[, -1]
#DBSCAN
dbscan_result <- dbscan(train_data_DF, eps = 5, minPts = 5)
print(dbscan_result)
#Gráfico com os clusters
pairs(train_data_DF, col = dbscan_result$cluster + 1L)
dbscan_result <- dbscan(train_data_DF, eps = 5, minPts = 30)
print(dbscan_result)
par(mfrow = c(1, 2))
pairs(train_data_DF, col = dbscan_result$cluster + 1L)
dbscan_result <- dbscan(train_data_DF, eps = 30, minPts = 5)
print(dbscan_result)
pairs(train_data_DF, col = dbscan_result$cluster + 1L)
dbscan_result <- dbscan(train_data_DF, eps = 60, minPts = 45)
print(dbscan_result)
pairs(train_data_DF, col = dbscan_result$cluster + 1L)
pairs(train_data_DF, col = filtered_train_data_dbscan$V1)
train_data_nb <- filtered_train_data_pixels_to_keep[, -1]
train_labels_nb <- as.factor(filtered_train_data_pixels_to_keep$V1)
test_data_nb <- filtered_test_data_pixels_to_keep[, -1]
test_labels_nb <- as.factor(filtered_test_data_pixels_to_keep$V1)
for (pixel in names(train_data_nb)) {
# Filtrar dados para a letra 'D' (label_D = 13)
train_data_D <- train_data_nb[train_labels_nb == label_D, ][[pixel]]
# Filtrar dados para a letra 'F' (label_F = 15)
train_data_F <- train_data_nb[train_labels_nb == label_F, ][[pixel]]
# Teste de Shapiro-Wilk para a letra 'D'
shapiro_result_D <- shapiro.test(train_data_D)
cat("Pixel:", pixel, "- Letra D\n")
cat("Estatística W:", shapiro_result_D$statistic, "\n")
cat("Valor-p:", shapiro_result_D$p.value, "\n\n")
# Teste de Shapiro-Wilk para a letra 'F'
shapiro_result_F <- shapiro.test(train_data_F)
cat("Pixel:", pixel, "- Letra F\n")
cat("Estatística W:", shapiro_result_F$statistic, "\n")
cat("Valor-p:", shapiro_result_F$p.value, "\n\n")
}
# Classificação Naive Bayes Paramétrica (já existente)
model_nb_parametric <- naive_bayes(train_data_nb, train_labels_nb)
predictions_nb_parametric <- predict(model_nb_parametric, test_data_nb, type = "class")
# Classificação Naive Bayes Não Paramétrica
model_nb_nonparametric <- naive_bayes(train_data_nb, train_labels_nb, usekernel = TRUE, kernel = "triangular")
predictions_nb_nonparametric <- predict(model_nb_nonparametric, test_data_nb, type = "class")
#Tipos de Kernel:
#gaussian: Kernel Gaussiano (padrão)
#rectangular: Kernel Retangular (ou Uniforme)
#triangular: Kernel Triangular
#epanechnikov: Kernel Epanechnikov
#biweight: Kernel Biweight (ou Quartic)
#cosine: Kernel Cosseno
#optcosine: Kernel Cosseno Otimizado
# Comparação dos Resultados
cat("\nMatriz de Confusão - Naive Bayes Paramétrico:\n")
conf_matrix_detailed_parametric <- confusionMatrix(predictions_nb_parametric, test_labels_nb)
print(conf_matrix_detailed_parametric)
cat("\nMatriz de Confusão - Naive Bayes Não Paramétrico:\n")
conf_matrix_detailed_nonparametric <- confusionMatrix(predictions_nb_nonparametric, test_labels_nb)
print(conf_matrix_detailed_nonparametric)
# PCA apenas nos dados de treino
train_data_pca <- filtered_train_data[, -1]
# Normalização dos dados
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca_scaled <- scale(train_data_pca)
# Realizar PCA
pca_model <- prcomp(train_data_pca_scaled)
# Variância explicada por cada componente principal
explained_variance <- pca_model$sdev^2 / sum(pca_model$sdev^2) * 100
cat("Variância explicada pela primeira componente principal:", round(explained_variance[1], 2), "%\n")
# Gráfico da variância explicada por cada componente principal
fviz_eig(pca_model, choice = "variance", ggtheme = theme_minimal(), title = "Variância Explicada por Componente Principal")
# Carregamentos da primeira componente principal
loadings_pc1 <- pca_model$rotation[, 1]
# Encontrar os 10 pixels com os maiores pesos absolutos na primeira componente principal
top_10_pixels <- head(sort(abs(loadings_pc1), decreasing = TRUE), 10)
cat("\n10 pixels mais importantes na primeira componente principal:\n")
print(top_10_pixels)
# PCA apenas nos dados de treino
train_data_pca <- filtered_train_data[, -1]
# Normalização dos dados
train_data_pca <- train_data_pca[, apply(train_data_pca, 2, var) != 0]
train_data_pca_scaled <- scale(train_data_pca)
# Realizar PCA
pca_model <- prcomp(train_data_pca_scaled)
# Variância explicada por cada componente principal
explained_variance <- pca_model$sdev^2 / sum(pca_model$sdev^2) * 100
cat("Variância explicada pela primeira componente principal:", round(explained_variance[1], 2), "%\n")
# Gráfico da variância explicada por cada componente principal
fviz_eig(pca_model, choice = "variance", ggtheme = theme_minimal(), title = "Variância Explicada por Componente Principal")
# Carregamentos da primeira componente principal
loadings_pc1 <- pca_model$rotation[, 1]
# Encontrar os 10 pixels com os maiores pesos absolutos na primeira componente principal
top_10_pixels <- head(sort(abs(loadings_pc1), decreasing = TRUE), 10)
cat("\n10 pixels mais importantes na primeira componente principal:\n")
print(top_10_pixels)
# Criar um vetor com os nomes dos pixels mais importantes
all_pixels <- c(names(top_10_pixels))
for (pixel_name in all_pixels) {
pixel_values <- filtered_train_data[, pixel_name]
# Criar um dataframe para o boxplot
boxplot_df <- data.frame(
Intensidade = pixel_values,
Letra = character_labels  # Rótulos das letras ('D' ou 'F')
)
# Criar e exibir o boxplot
boxplot(Intensidade ~ Letra, data = boxplot_df,
main = paste("Distribuição da Intensidade do Pixel", pixel_name),
xlab = "Letra", ylab = "Intensidade do Pixel",
col = c("blue", "red"))
}
# Combina as amostras de treino e teste num só dataset
filtered_combined_data <- rbind(filtered_train_data, filtered_test_data)
# Remove as colunas com zero variância
filtered_combined_data <- filtered_combined_data[, apply(filtered_combined_data, 2, var) != 0]
filtered_combined_data <- data.frame(lapply(filtered_combined_data, as.numeric))
# PCA
filtered_combined_data_pca <- prcomp(filtered_combined_data, scale. = TRUE)
# Calcula a variância explicada por cada componente principal
explained_variance <- filtered_combined_data_pca$sdev^2 / sum(filtered_combined_data_pca$sdev^2)
# Calcula a variância explicada cumulativa
cumulative_variance <- cumsum(explained_variance)
# Número de componentes que explicam pelo menos 80% da variância
num_components <- which(cumulative_variance >= 0.80)[1]
cat("Número de componentes que explicam pelo menos 80% da variância:", num_components, "\n")
pca_scores <- filtered_combined_data_pca$x
train_indices <- 1:4800
test_indices <- 4801:5600
# Filtrar os dados PCA para conter apenas os componentes principais selecionados
filtered_train_data_pca_split <- pca_scores[train_indices, 1:num_components]
filtered_test_data_pca_split <- pca_scores[test_indices, 1:num_components]
# Amostra de treino e teste para o modelo SMV
filtered_train_data_split <- filtered_combined_data[train_indices, ]
filtered_test_data_split <- filtered_combined_data[test_indices, ]
execute_svm <<- function(train_data, train_labels, test_data, test_labels)
{
svm_model <- svm(train_data, train_labels, type = 'C-classification', kernel="polynomial",
probability = TRUE)
predictions <- predict(svm_model, test_data, probability = TRUE)
conf_matrix_detailed <- confusionMatrix(predictions, test_labels)
print(conf_matrix_detailed)
return(attributes(predictions)$probabilities)
}
# Classificaçao sem PCA
train_data_svm <- filtered_train_data_split[, -1]
train_labels_svm <- as.factor(filtered_train_data_split$V1)
test_data_svm <- filtered_test_data_split[, -1]
test_labels_svm <- as.factor(filtered_test_data_split$V1)
cat("\nMatriz de Confusão - Sem PCA:\n")
result_svm <- execute_svm(train_data_svm, train_labels_svm, test_data_svm, test_labels_svm)
# Classificaçao com PCA
train_data_svm_pca <- filtered_train_data_pca_split
train_labels_svm_pca <- as.factor(filtered_train_data_split$V1)
test_data_svm_pca <- filtered_test_data_pca_split
test_labels_svm_pca <- as.factor(filtered_test_data_split$V1)
cat("\nMatriz de Confusão - Com PCA:\n")
result_svm_pca <- execute_svm(train_data_svm_pca, train_labels_svm_pca, test_data_svm_pca, test_labels_svm_pca)
# Carregar a biblioteca 'pROC' para utilizar a função 'roc'
library(pROC)
# Função para obter a probabilidade da classe positiva
get_prob_positive <- function(predictions, positive_class) {
return(predictions[, positive_class])
}
# Curva ROC sem PCA
roc_svm <- roc(test_labels_svm, get_prob_positive(result_svm, 2))
# Curva ROC com PCA
roc_svm_pca <- roc(test_labels_svm_pca, get_prob_positive(result_svm_pca, 2))
# Plotar ambas as curvas ROC no mesmo gráfico
plot(roc_svm, col = "blue", main = "Curvas ROC - SVM com e sem PCA", print.auc.col = "blue",
axes=FALSE,
ylab = "Sensibilidade",
xlab = "1-Especificidade")
plot(roc_svm_pca, col = "red", add = TRUE, print.auc.col = "red")
legend("bottomright", legend = c("Sem PCA", "Com PCA"), col = c("blue", "red"), lwd = 2)
axis(side = 2, at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
labels = expression(0, 0.2, 0.4, 0.6, 0.8, 1), cex.axis = 1, pos=1)
axis(side = 1, at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
labels = expression(1, 0.8, 0.6, 0.4, 0.2, 0),
pos=-0.001,
cex.axis = 1)
# Primeiras duas componentes principais
pca_data <- pca_model$x[, 1:2]
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "complete")
# Dendograma
plot(hc, main = "Dendrograma - Clustering Hierárquico", xlab = "", sub = "")
# Primeiras duas componentes principais
pca_data <- pca_model$x[, 1:2]
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "simple")
# Primeiras duas componentes principais
pca_data <- pca_model$x[, 1:2]
# Hierarchical cluster analysis
hc <- hclust(dist(pca_data), method = "complete")
# Dendograma
plot(hc, main = "Dendrograma - Clustering Hierárquico", xlab = "", sub = "")
# Informação Silhouette
silhouette_info <- silhouette_scores$data
# Fila com maior valor
optimal_row <- silhouette_info[which.max(silhouette_info$y), ]
# Número ótimo de clusters
optimal_clusters <- optimal_row$clusters
silhouette_avg <- optimal_row$y
optimal_cluster_labels <- cutree(hc, optimal_clusters)
# Calculate silhouette values for the optimal clustering
sil <- silhouette(optimal_cluster_labels, dist(pca_data))
fviz_silhouette(sil)
# Perform k-means cluster analysis with the optimal number of clusters
kmeans_result <- kmeans(pca_data, centers = 2, nstart = 25)
# Calculate silhouette information
sil <- silhouette(kmeans_result$cluster, dist(pca_data))
# Plot the silhouette graph
fviz_silhouette(sil)
# Calculate the silhouette score
print(paste("Optimal Number of Clusters:", optimal_clusters))
print(paste("Silhouette Score:", silhouette_avg))
# Compare the predicted clusters with the true labels
comparison_df <-
data.frame(True_Labels = filtered_test_data$V1,
Predicted_Clusters = kmeans_result$cluster[1:nrow(filtered_test_data)])
print(head(comparison_df, 20))
# Informação Silhouette
silhouette_info <- silhouette_scores$data
# Fila com maior valor
optimal_row <- silhouette_info[which.max(silhouette_info$y), ]
# Número ótimo de clusters
optimal_clusters <- optimal_row$clusters
silhouette_avg <- optimal_row$y
optimal_cluster_labels <- cutree(hc, optimal_clusters)
# Calculate silhouette values for the optimal clustering
sil <- silhouette(optimal_cluster_labels, dist(pca_data))
fviz_silhouette(sil)
# Informação Silhouette
silhouette_info <- silhouette_scores$data
print(silhouette_info)
# Fila com maior valor
optimal_row <- silhouette_info[which.max(silhouette_info$y), ]
# Número ótimo de clusters
optimal_clusters <- optimal_row$clusters
silhouette_avg <- optimal_row$y
optimal_cluster_labels <- cutree(hc, optimal_clusters)
# Calculate silhouette values for the optimal clustering
sil <- silhouette(optimal_cluster_labels, dist(pca_data))
fviz_silhouette(sil)
